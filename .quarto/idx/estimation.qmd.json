{"title":"Introduction to Inferential Statistics","markdown":{"headingText":"Introduction to Inferential Statistics","containsRefs":false,"markdown":"\n```{r}\nrm(list = ls())\nlibrary(tidyverse)\nlibrary(rstatix)\nlibrary(easystats)\nlibrary(ggfortify)\nlibrary(ggpubr)\nlibrary(jtools)\nlibrary(pubh)\nlibrary(sjlabelled)\nlibrary(sjPlot)\nlibrary(sjmisc)\n\nimport::from(latex2exp, TeX)\nimport::from(epiDisplay, ci)\nimport::from(mosaic, xpnorm, xqnorm)\ntheme_set(sjPlot::theme_sjplot2(base_size = 10))\ntheme_update(legend.position = \"top\")\noptions('huxtable.knit_print_df' = FALSE)\noptions('huxtable.autoformat_number_format' = list(numeric = \"%5.2f\"))\nknitr::opts_chunk$set(comment = NA, dpi = 300, \n                      fig.width = 6, fig.height = 4)\n```\n\n## Overview\n\nTo infer general conclusions at a population level from relatively small samples is important to have an unbiased sampling technique, so the sample *represents* the original population.\n\nAs an introduction to inferential statistics, we will look at sampling distributions, the concept of standard error and estimation of confidence intervals for continuous variables. We will also look at some aspects associated with study design including basic sample size calculations.\n\nOnce you have completed this laboratory, you should feel comfortable:\n\n-   Obtaining random samples from populations.\n-   Estimating reference range.\n-   Estimating confidence intervals around the mean.\n-   Estimating confidence intervals around proportions.\n-   Estimating confidence intervals around counts.\n-   Estimating sample sizes for studies comparing means.\n-   Estimating sample sizes for studies comparing proportions.\n\n> **Summary of New Commands**\n\n| **Command**         | **Library**  | **Function**                                            |\n|---------------------|--------------|---------------------------------------------------------|\n| **as.numeric**      | *base*       | Coerces objects of type \"numeric\"                       |\n| **bst**             | *pubh*       | Estimates bootstrap confidence intervals for the mean   |\n| **ci**              | *epiDisplay* | Estimates confidence intervals                          |\n| **gf_dist**         | *ggformula*  | Constructs density plots for theoretical distributions  |\n| **n.for.2means**    | *epiDisplay* | Sample size for comparing two means                     |\n| **n.for.2p**        | *epiDisplay* | Sample size for comparing two proportions               |\n| **power.t.test**    | *stats*      | Power calculations for means                            |\n| **prop_ord**        | *pubh*       | Calculates a proportion from OR and a second proportion |\n| **reference_range** | *pubh*       | Calculated the reference interval                       |\n| **slice_sample**    | *dplyr*      | Takes random samples                                    |\n| **t_test**          | *rstatix*    | Performs $t$-tests                                      |\n| **xpnorm**          | *mosaic*     | Calculates probabilities for the Normal distribution    |\n| **xqnorm**          | *mosaic*     | Calculates $z$ values for the Normal distribution       |\n\n## Introduction\n\nTo understand probability distributions, we will use the following variables\n\n| **Variable** | **Distribution** | **Dataset**         |\n|--------------|------------------|---------------------|\n| `chd`        | Binomial         | `wcgs`              |\n| `ncigs`      | Poisson          | `wcgs`              |\n| `height`     | Normal           | `wcgs`              |\n| `IgM`        | Log-Normal       | `IgM` (from `ISwR`) |\n| `age`        | Not normal       | `wcgs`              |\n| `dbp`        | Not normal       | `wcgs`              |\n\nWe start by loading data into our session:\n\n```{r}\nwcgs = read_rds('data/wcgs.rds')\ndata(IgM, package = \"ISwR\")\n```\n\n`IgM` is a vector, hence we will create a dataset which includes the vector.\n\n```{r}\nserum = tibble(IgM)\n```\n\n### The Normal distribution\n\n:::{.callout-tip}\n## Example\n\nA normal curve was calculated from the diastolic blood pressures of 500 men (mean 82 mm Hg, standard deviation 10 mm Hg). What is the probability of finding a man with a DBP \\> 72 mm Hg if we assume a normal distribution?\n:::\n\nBefore we answer this problem, we need to think about our answer. By definition, the mean value is at the centre, so the area under the curve (AUC) AUC = 50% to each side. As the value of 72 is less than the mean (82), we already know that the solution has to be greater than 50%.\n\nThe function `xpnorm` gives us the AUC to the left of the given value (meaning *less than*). As the total AUC = 1, to find probabilities *higher than* we can subtract from 1.\n\n```{r}\n1 - xpnorm(72, mean = 82, sd = 10)\n```\n\n:::{.callout-tip}\n## Exercise\n\nWhat is the probability of finding a man with a DBP \\< 65 mm Hg in our current example?\n:::\n\n```{r}\n#| code-fold: true\nxpnorm(65, mean = 82, sd = 10)\n```\n\nWhat would be the value of DBP which would contain 97.5% of the population (to the left of the curve)?\n\nThis is the opposite problem than the previous one. Now we know the probability and would like to know the value that would contain that probability. For finding *quantiles* in the normal curve, we use `qnorm`.\n\n```{r}\nxqnorm(0.975, mean = 82, sd = 10)\n```\n\n:::{.callout-tip}\n## Exercise\n\nWhat would be value of DBP which would contain 2.5% of the population (to the left of the curve)?\n:::\n\n```{r}\n#| code-fold: true\nxqnorm(0.025, mean = 82, sd = 10)\n```\n\nSo, the limits that would contain 95% of the population around the mean are:\n\n```{r}\nreference_range(82, 10) %>%\n  round(2)\n```\n\nWhich $z$-value would contain 97.5% of the standard normal curve?\n\n```{r}\nxqnorm(0.975)\n```\n\n:::{.callout-note}\nFor a normal distribution: 95% of the population is within $\\approx 2$ standard deviations around the mean; 99% of the population is within $\\approx 3$ standard deviations around the mean.\n:::\n\n:::{.callout-tip}\n## Exercise\n\nConstruct a table of the following statistics: mean, standard deviation, median and skewness for the variable `height` from the `wcgs` dataset.\n:::\n\n```{r}\n#| label: tbl-tbl1\n#| tbl-cap: \"Descriptive statistics of height.\"\n#| code-fold: true\ntab1 = wcgs %>%\n  descr(height) %>%\n  select(label, mean, sd, md, skew)\n\nlabs = c(\"\", \"Mean\", \"SD\", \"Median\", \"Skewness\")\nnames(tab1) = labs\n\ntab1 %>%\n  as_hux()\n```\n\n:::{.callout-tip}\n## Exercise \n\nConstruct a histogram with a normal density plot and a QQ-plot for the variable `height` from the `wcgs` dataset.\n:::\n\n```{r}\n#| code-fold: true\np1 = wcgs %>%\n  hist_norm(~ height, title = \"(a)\") %>%\n  axis_labs()\n\np2 = wcgs %>%\n  qq_plot(~ height, title = \"(b)\") %>%\n  axis_labs()\n\nautoplot(list(p1, p2))\n```\n\n:::{.callout-tip}\n## Question\n\nWhat are your conclusions?\n:::\n\n:::{.callout-note}\n## Answer\n\nHeight in males follows a normal distribution.\n:::\n\n:::{.callout-tip}\n## Exercise\n\nIs DBP normally distributed in the subset of males who did not have a CHD event in the `wcgs` dataset? Construct a table of the following statistics: mean, standard deviation, median, and skewness for the variable `dbp` from the `wcgs` dataset.\n:::\n\n```{r}\n#| label: tbl-tbl2\n#| tbl-cap: \"Descriptive statistics of diastolic blood pressure.\"\n#| code-fold: true\ntab2 = wcgs %>%\n  descr(dbp) %>%\n  select(label, mean, sd, md, skew)\n\nnames(tab2) = labs\n\ntab2 %>%\n  as_hux()\n```\n\n:::{.callout-tip}\n## Exercise\n\nConstruct a histogram with a normal density plot and a QQ-plot for the variable `dbp` from the `wcgs` dataset.\n:::\n\n```{r}\n#| code-fold: true\np1 = wcgs %>%\n  filter(chd == \"No CHD\") %>%\n  hist_norm(~ dbp, title = \"(a)\") %>%\n  axis_labs()\n\np2 = wcgs %>%\n  filter(chd == \"No CHD\") %>%\n  qq_plot(~ dbp, title = \"(b)\") %>%\n  axis_labs()\n\nautoplot(list(p1, p2))\n```\n\n### Log-normal distribution\n\n:::{.callout-tip}\n## Exercise:\n\nConstruct a table of the following statistics: mean, standard deviation, median and skewness for the variable `IgM` from the `serum` dataset.\n:::\n\n```{r}\n#| label: tbl-tbl3\n#| tbl-cap: \"Descriptive statistics of serum IgM.\"\n#| code-fold: true\ntab3 = serum %>%\n  descr(IgM) %>%\n  select(label, mean, sd, md, skew)\n\nnames(tab3) = labs\n\ntab3 %>%\n  as_hux()\n```\n\n:::{.callout-tip}\n## Exercise\n\nConstruct a histogram with a normal density plot and a QQ-plot for the variable `IgM`.\n:::\n\n```{r}\n#| code-fold: true\np1 = serum %>%\n  hist_norm(~ IgM, title = \"(a)\",\n          xlab = \"IgM (mg/ml)\")\n\np2 = serum %>%\n  qq_plot(~ IgM, title = \"(b)\",\n          ylab = \"IgM (mg/ml)\")\n\nautoplot(list(p1, p2))\n```\n\n:::{.callout-tip}\n## Question\n\nWhat are your conclusions?\n:::\n\n:::{.callout-note}\n## Answer\n\n`IgM` is not normally distributed as it has a positive skew. The QQ-plot shows deviations from normality and shows a J-shape.\n:::\n\n:::{.callout-tip}\n## Exercise\n\nConstruct a histogram with a normal density plot and a QQ-plot for log-transformed version of `IgM.` (tip: use `~ log(IgM)` in your formula).\n:::\n\n```{r}\n#| code-fold: true\np1 = serum %>%\n  hist_norm(~ log(IgM), title = \"(a)\")\n\np2 = serum %>%\n  qq_plot(~ log(IgM), title = \"(b)\")\n\nautoplot(list(p1, p2))\n```\n\n:::{.callout-tip}\n## Question\n\nWhat are your conclusions?\n:::\n\n:::{.callout-note}\n## Answer\n\nWhen log-transformed, `IgM` follows a normal distribution.\n:::\n\n## Random Sampling\n\nWhen we take a sample, we calculate a *statistic*, an estimate of a *parameter* in the original population where the sample was initially taken.\n\nThis process, of statistical inference is reliable and robust if the process is not biased. One way to avoid bias is through random sampling. The function `sample` allows us to take random samples from variables.\n\nTo have the same results, we will set up a seed before the sampling\n\n```{r}\nset.seed(576)\n```\n\nLook at the statistics from random samples with decreasing sample size.\n\n```{r}\nrbind(\n  wcgs %>% estat(~ height),\n  wcgs %>% slice_sample(n = 100) %>% \n    copy_labels(wcgs) %>% estat(~ height),\n  wcgs %>% slice_sample(n = 50) %>% \n    copy_labels(wcgs) %>% estat(~ height),\n  wcgs %>% slice_sample(n = 25) %>% \n    copy_labels(wcgs) %>% estat(~ height),\n  wcgs %>% slice_sample(n = 10) %>% \n    copy_labels(wcgs) %>% estat(~ height)\n)\n```\n\nSo, even with a sample size as small as $n = 25$, the statistics are still a good estimate of the original values in the population.\n\nHeight is a continues variable that follows a normal distribution, what is the case for categorical variables?\n\n```{r}\nwcgs %>% freq_table(chd)\n\nwcgs %>% slice_sample(n = 100) %>% freq_table(chd)\n\nwcgs %>% slice_sample(n = 50) %>% freq_table(chd)\n\nwcgs %>% slice_sample(n = 25) %>% freq_table(chd)\n\nwcgs %>% slice_sample(n = 10) %>% freq_table(chd)\n```\n\n## Confidence Intervals\n\nReference range and confidence intervals are not the same.\n\n-   The reference range is about the limits that would contain 95% of the observations in a sample or population.\n\n-   The confidence interval is about the limits that would contain a given proportion (most of the times, 95%; sometimes, 99%) of the true value of a given parameter (e.g., the mean) in a population.\n\nFor the calculation of the reference range, we used about two standard deviations ($\\sim$ 1.96) around the mean (as we assumed a normal distribution). For the confidence interval, we use about two standard errors around the mean.\n\n## $t$-distribution\n\nThe $t$-distribution is also bell shaped, but with a heavier tail. It has one more parameter than the normal distribution: the degrees of freedom (df). For our current example:\n\n$$df = n-1$$\n\nwhere $n$ is the sample size. As the sample size increases, the $t$-distribution is almost the same as the normal distribution (for $n>30$).\n\nFor illustration purposes, let's take a look at the density plot of a $t$-distribution.\n\n```{r}\ngf_dist(\"t\", df = 5)\n```\n\nIn the next lab, we will learn about hypothesis testing. In `R` every time we do hypothesis testing, a confidence interval is also shown.\n\nA calculation of the 95% CI for continuous variables can be estimated with the argument `detailed = TRUE` in `t_test`. For example, for `height` the CI is:\n\n```{r}\nwcgs %>% \n  t_test(height ~ 1, detailed = TRUE) %>% \n  as.data.frame()\n```\n\nWe can also use the function `ci` from `epiDisplay`:\n\n```{r}\nwcgs %$% ci(height)\n```\n\n### Introduction to Bootstrap\n\nThe advantage of bootstrap is that we can generate a big number of means (most of the times in the order of thousand or ten thousand) even from small samples, to estimate a narrower CI (as our sample of means is greater than the number of observations in our original sample).\n\nThe function `bst` from the `pubh` package allows us to estimate CI around the mean.\n\n```{r}\nwcgs %$% bst(height)\n```\n\nAs an example, the 99% bootstrap CI for the mean value of `height`, using ten thousand replicates, would be:\n\n```{r}\nwcgs %$% bst(height, n = 1e4, CI = 99)\n```\n\n### Confidence intervals for proportions\n\nA calculation of the 95% CI for binomial variables can be estimated with the function `ci`. For example, for `chd` the CI is:\n\n```{r}\nwcgs %$% ci(chd) %>% round(3)\n```\n\n:::{.callout-tip}\n## Question\n\nWhat is your interpretation?\n:::\n\n:::{.callout-note}\n## Answer\n\nThe prevalence of coronary heart disease in the population of males where the WCGS was sampled was: 8.1% (95% CI: 7.2, 9.2%).\n:::\n\n## Sample Size\n\nWe will not need a data set for this section. The command for power and sample size for means is `power.t.test` from the `stats` library. For proportions, the command is `n.for.2p` from the `epiDisplay` library.\n\n### One-sample mean\n\n:::{.callout-tip}\n## Example\n\nConsider a study of the effect of a calcium channel blocking agent on heart rate for patients with unstable angina. Suppose we want to have at least 80% power for detecting a significant difference if the smallest clinically interesting effect of the drug is to change mean heart rate by five beats per minute (bpm) over 48 hours. Assume that the standard deviation for changes in bpm over 48 hours is ten bpm. How many patients should be enrolled in such a study? This is a one-sample test (paired $t$-test on a change in heart rate).\n:::\n\n```{r}\npower.t.test(delta = 5, sd = 10, sig.level = 0.05, \n             power = 0.80, type = \"one.sample\")\n```\n\n:::{.callout-tip}\n## Example\n\nWe wish to test the effects of a low-fat diet on serum cholesterol levels. We will measure the difference in cholesterol level for each subject before and after being on a diet. We will consider a reduction in 10 mg/dl as significant. We wish to have a power of 0.80 with a $\\sigma$ = 0.05. From previous studies, we know that the standard deviation of the difference in cholesterol would be about 50 mg/dl.\n:::\n\n```{r}\npower.t.test(delta = 10, sd = 50, sig.level = 0.05, \n             power = 0.80, type = \"one.sample\")\n```\n\n### Two-sample means\n\n:::{.callout-tip}\n## Example\n\nSuppose that instead of a single group design, they had a control group also, and the researches would like to compare the cholesterol levels at two months post-intervention. If they assume equal variances, what is the estimated sample size then?\n:::\n\n```{r}\npower.t.test(delta = 10, sd = 50, sig.level = 0.05, \n             power = 0.80)\n```\n\nWhen comparing two means, we can also use `n.for.2means` which has the advantage of allowing different values of standard deviations for each sample (not the case in our current example).\n\n```{r}\nlibrary(epiDisplay)\nn.for.2means(mu1 = 0, mu2 = 10, sd1 = 50, sd2 = 50)\n```\n\nIt is often the case that we have a limited sample size, due to the availability of participants or due to time or funding.\n\n:::{.callout-tip}\n## Example\n\nSuppose you would like to test the effects of caffeine on time to exhaustion in trained cyclists, 10% below their anaerobic threshold. You believe that a difference of 1 minute is meaningful, and you have 12 willing participants whom you will randomise to placebo or caffeine. From a review of the literature, it appears that a reasonable estimate for the standard deviation is 1.5 minutes. What is the power of this study, assuming a two-sided test using $\\sigma$ = 0.05?\n:::\n\n```{r}\npower.t.test(delta = 1, sd = 1.5, sig.level = 0.05, n = 6)\n```\n\nWhat should you do? How big would your sample size have to be to have 80% power?\n\n```{r}\npower.t.test(delta = 1, sd = 1.5, sig.level = 0.05, power = 0.8)\n```\n\n### Two-sample proportions\n\n:::{.callout-tip}\n## Example\n\nA scientist wants to compare rates of prematurity in infants born to women who attend prenatal clinics ($p_1$ = 0.25) with non-attenders ($p_2$ = 0.40). Because recruitment of non-attenders is difficult, the scientist decides to study half as many non-attenders (ratio = 2). Find $n_1$ and $n_2$ to ensure $\\sigma$ = 0.01 and 95% power.\n:::\n\n```{r}\nn.for.2p(p1 = 0.25, p2 = 0.4, alpha = 0.01, power = 0.95, ratio = 0.5)\n```\n\n:::{.callout-tip}\n## Example\n\nA cohort study of smoking and coronary heart disease (CHD) in middle-aged men is planned. A sample of men will be selected at random from the population and will be asked to complete a questionnaire. The follow-up period will be five years. The investigators would like to be 0.90 sure of being able to detect when the risk ratio of CHD is 1.4 for smokers, using a 0.05 significance test. Previous evidence suggests that the death rate in non-smokers is 413 per 100000 per year. Assuming equal numbers of smokers and non-smokers are sampled, how many should be sampled overall?\n:::\n\n```{r}\nn.for.2p(p1 = 5 * 413/1e5, p2 = 1.4 * 5 * 413/1e5, power = 0.9)\n```\n\n:::{.callout-note}\nThe proportion of the control group (non-smokers) is: (5 $\\times$ 413/100000) whereas the proportion for the exposed group (smokers) is 1.4 times greater.\n:::\n\n:::{.callout-tip}\n## Example\n\nA case-control study of the relationship between smoking and CHD is planned. A sample of men with newly diagnosed CHD will be compared for smoking status with a sample of controls. Assuming an equal number of cases and controls, how many are needed to detect an approximate odds ratio of 2.0 with 0.90 power using a two-sided 0.05 test? Previous surveys indicate that 0.30 of the male population are smokers.\n:::\n\n```{r}\nprop_or(p2 = 0.3, or = 2)\n```\n\nIn other words, in the *healthy*, control group we have 30% of smokers, and we expect a 46% of smokers in the CHD group to achieve, at least, an OR = 2.\n\n```{r}\nn.for.2p(p1 = 0.3, p2 = prop_or(p2 = 0.3, or = 2), power = 0.9)\n```\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":6,"fig-height":4,"fig-format":"retina","fig-dpi":300,"df-print":"default","error":true,"eval":true,"cache":null,"freeze":"auto","echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc-depth":3,"output-file":"estimation.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","bibliography":["packages.bib"],"csl":"the-american-statistician.csl","theme":"minty","number-depth":3,"highlight":"kate"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}